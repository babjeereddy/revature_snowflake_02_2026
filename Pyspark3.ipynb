{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21a69ef-6f78-44f6-a7d0-bb3cadd8789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName(\"Spark Demo\")\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd03ad-ed42-418e-9d9c-f24e45014876",
   "metadata": {},
   "outputs": [],
   "source": [
    "A PySpark DataFrame is a distributed, schema-based table that allows you to process \n",
    "large-scale data efficiently using Sparkâ€™s optimized engine.\n",
    "\n",
    "Why DataFrame in PySpark?\n",
    "Before DataFrames, Spark mainly used RDD (Resilient Distributed Dataset).\n",
    "DataFrames were introduced to:\n",
    "    Improve performance (via Catalyst Optimizer)\n",
    "    Provide SQL-like querying\n",
    "    Simplify big data processing\n",
    "    Reduce code complexity\n",
    "\n",
    "When to Use DataFrame?\n",
    "    Use PySpark DataFrame when:\n",
    "    Working with structured data\n",
    "    Writing SQL-like queries\n",
    "    Performance matters\n",
    "    Handling large datasets (GBs/TBs/PBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817c5036-faf0-4251-9e45-66daf8147541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  2|\n",
      "|  4|\n",
      "|  6|\n",
      "|  8|\n",
      "| 10|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df =spark.range(0,11,2)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2636d59-4271-4c8f-a06c-1d99574d5d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f344ad3f-9f23-4af7-8055-67cf670fdfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23da09d4-e50c-4762-91ec-595b69e2be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df930e9-c433-4b7c-838b-7a36f786bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff13b06a-0f77-4825-b391-ddd3934907a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c127648-be85-4fe9-a3b0-9fdf2076b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  2|Priya| 60000|\n",
      "|  3| John| 45000|\n",
      "+---+-----+------+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe using list of tuples\n",
    "data = [\n",
    "    (1, \"Ravi\", 50000),\n",
    "    (2, \"Priya\", 60000),\n",
    "    (3, \"John\", 45000)\n",
    "]\n",
    "\n",
    "columns = 'id int,name string,salary int'\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd72892a-2419-496a-9d38-d951d5e73d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id int', 'bigint'), ('name string', 'string'), ('salary float', 'bigint')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae06a8-684f-4d47-b4a8-9014171494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "In PySpark, StructType is used to define the schema (structure) of a DataFrame explicitly.\n",
    "It tells Spark:\n",
    "    Column names\n",
    "    Data types\n",
    "    Whether a column can contain null values\n",
    "    Nested structure (complex columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214480c-208f-47f9-afe6-f7f0c6f7d475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb49afa5-4055-40bc-abf0-ef2b86a88628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| id|  name|age|\n",
      "+---+------+---+\n",
      "|  1| Kumar| 28|\n",
      "|  2| Anita| 32|\n",
      "|  3|George| 40|\n",
      "+---+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating data frame wit schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "data = [\n",
    "    (1, \"Kumar\", 28),\n",
    "    (2, \"Anita\", 32),\n",
    "    (3, \"George\", 40)\n",
    "]\n",
    "df2 = spark.createDataFrame(data, schema)\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9996989-97c6-464f-a320-09e925b77dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=2, name='Priya', salary=60000), Row(id=3, name='John', salary=45000)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "434f83b9-d0d3-46bf-9776-1dfe13f1f0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'), ('name', 'string'), ('age', 'int')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3f0ab0-9adc-4898-966c-66e38ee4c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  2|Priya| 60000|\n",
      "|  3| John| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe using dictionary\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Ravi\", \"salary\": 50000},\n",
    "    {\"id\": 2, \"name\": \"Priya\", \"salary\": 60000},\n",
    "    {\"id\": 3, \"name\": \"John\", \"salary\": 45000}\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9074499e-e5cd-47e8-8f96-5f95be5fcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.csv('c:/data/Orders1', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3364649c-f0b7-4c27-9886-f689f5d89133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "627a6696-f2e0-44e3-b9b2-3af5995f20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|         status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('c:/data/Orders1', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5f9d65-7236-4450-a226-aa282d171431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, order_id: string, customer_id: string, status: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d253e0-f73b-4d19-ae00-6d7234094e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4f7373f-10cf-4345-87a4-3a64b904f712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|orderId|         status|\n",
      "+-------+---------------+\n",
      "|      1|         CLOSED|\n",
      "|      2|PENDING_PAYMENT|\n",
      "|      3|       COMPLETE|\n",
      "|      4|         CLOSED|\n",
      "|      5|       COMPLETE|\n",
      "|      6|       COMPLETE|\n",
      "|      7|       COMPLETE|\n",
      "|      8|     PROCESSING|\n",
      "|      9|PENDING_PAYMENT|\n",
      "|     10|PENDING_PAYMENT|\n",
      "|     11| PAYMENT_REVIEW|\n",
      "|     12|         CLOSED|\n",
      "|     13|PENDING_PAYMENT|\n",
      "|     14|     PROCESSING|\n",
      "|     15|       COMPLETE|\n",
      "|     16|PENDING_PAYMENT|\n",
      "|     17|       COMPLETE|\n",
      "|     18|         CLOSED|\n",
      "|     19|PENDING_PAYMENT|\n",
      "|     20|     PROCESSING|\n",
      "+-------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"order_id\"].alias(\"orderId\"), df[\"status\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b680b5b-117b-4498-b41f-25c046a9b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|orderId|    orderStatus|\n",
      "+-------+---------------+\n",
      "|      1|         CLOSED|\n",
      "|      2|PENDING_PAYMENT|\n",
      "|      3|       COMPLETE|\n",
      "|      4|         CLOSED|\n",
      "|      5|       COMPLETE|\n",
      "|      6|       COMPLETE|\n",
      "|      7|       COMPLETE|\n",
      "|      8|     PROCESSING|\n",
      "|      9|PENDING_PAYMENT|\n",
      "|     10|PENDING_PAYMENT|\n",
      "|     11| PAYMENT_REVIEW|\n",
      "|     12|         CLOSED|\n",
      "|     13|PENDING_PAYMENT|\n",
      "|     14|     PROCESSING|\n",
      "|     15|       COMPLETE|\n",
      "|     16|PENDING_PAYMENT|\n",
      "|     17|       COMPLETE|\n",
      "|     18|         CLOSED|\n",
      "|     19|PENDING_PAYMENT|\n",
      "|     20|     PROCESSING|\n",
      "+-------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(col(\"order_id\").alias(\"orderId\"), col(\"status\").alias(\"orderStatus\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8472d514-2ab9-4ed7-ab10-6d36716a395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+\n",
      "|order_id|hello|         status|\n",
      "+--------+-----+---------------+\n",
      "|       1|hello|         CLOSED|\n",
      "|       2|hello|PENDING_PAYMENT|\n",
      "|       3|hello|       COMPLETE|\n",
      "|       4|hello|         CLOSED|\n",
      "|       5|hello|       COMPLETE|\n",
      "|       6|hello|       COMPLETE|\n",
      "|       7|hello|       COMPLETE|\n",
      "|       8|hello|     PROCESSING|\n",
      "|       9|hello|PENDING_PAYMENT|\n",
      "|      10|hello|PENDING_PAYMENT|\n",
      "|      11|hello| PAYMENT_REVIEW|\n",
      "|      12|hello|         CLOSED|\n",
      "|      13|hello|PENDING_PAYMENT|\n",
      "|      14|hello|     PROCESSING|\n",
      "|      15|hello|       COMPLETE|\n",
      "|      16|hello|PENDING_PAYMENT|\n",
      "|      17|hello|       COMPLETE|\n",
      "|      18|hello|         CLOSED|\n",
      "|      19|hello|PENDING_PAYMENT|\n",
      "|      20|hello|     PROCESSING|\n",
      "+--------+-----+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df.select(\"order_id\",lit(\"hello\"),\"status\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5416719a-128e-4b03-acb3-b4a4783992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.withColumnRenamed(\"status\",\"OrderStatus\")\\\n",
    "  .withColumnRenamed(\"customer_id\",\"CustomerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdedcc05-a998-4fc8-a9a5-e7812cb793ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+---------------+\n",
      "|order_id|         order_date|CustomerId|    OrderStatus|\n",
      "+--------+-------------------+----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|     11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|       256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|     12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|      8827|         CLOSED|\n",
      "+--------+-------------------+----------+---------------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "df1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649fd952-057d-41c9-8f6e-adb10a2aac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='order_item_id int, order_id int, product_id int, quantity int, subtotal float, price float'\n",
    "ordItems_df = spark.read.csv('c:/data/OrderItems', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0738ddca-c691-4b84-a2c4-fb3b64db4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+------+\n",
      "|order_item_id|order_id|product_id|quantity|subtotal| price|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "|            1|       1|       957|       1|  299.98|299.98|\n",
      "|            2|       2|      1073|       1|  199.99|199.99|\n",
      "|            3|       2|       502|       5|   250.0|  50.0|\n",
      "|            4|       2|       403|       1|  129.99|129.99|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f02a846-f285-43d2-95bf-16b21a016589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_id: integer (nullable = true)\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- subtotal: float (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35d52757-7f25-4329-a6d1-eb32ecec5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d04b494-4a04-4e22-a318-eb8ceed6ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+------+------------------+\n",
      "|order_item_id|order_id|product_id|quantity|subtotal| price|          discount|\n",
      "+-------------+--------+----------+--------+--------+------+------------------+\n",
      "|            1|       1|       957|       1|  299.98|299.98|29.998001098632812|\n",
      "|            2|       2|      1073|       1|  199.99|199.99|19.999000549316406|\n",
      "|            3|       2|       502|       5|   250.0|  50.0|              25.0|\n",
      "|            4|       2|       403|       1|  129.99|129.99|12.999000549316406|\n",
      "|            5|       4|       897|       2|   49.98| 24.99|4.9979999542236335|\n",
      "|            6|       4|       365|       5|  299.95| 59.99|29.995001220703127|\n",
      "|            7|       4|       502|       3|   150.0|  50.0|              15.0|\n",
      "|            8|       4|      1014|       4|  199.92| 49.98|19.991999816894534|\n",
      "|            9|       5|       957|       1|  299.98|299.98|29.998001098632812|\n",
      "|           10|       5|       365|       5|  299.95| 59.99|29.995001220703127|\n",
      "|           11|       5|      1014|       2|   99.96| 49.98| 9.995999908447267|\n",
      "|           12|       5|       957|       1|  299.98|299.98|29.998001098632812|\n",
      "|           13|       5|       403|       1|  129.99|129.99|12.999000549316406|\n",
      "|           14|       7|      1073|       1|  199.99|199.99|19.999000549316406|\n",
      "|           15|       7|       957|       1|  299.98|299.98|29.998001098632812|\n",
      "|           16|       7|       926|       5|   79.95| 15.99|7.9949996948242195|\n",
      "|           17|       8|       365|       3|  179.97| 59.99|17.997000122070315|\n",
      "|           18|       8|       365|       5|  299.95| 59.99|29.995001220703127|\n",
      "|           19|       8|      1014|       4|  199.92| 49.98|19.991999816894534|\n",
      "|           20|       8|       502|       1|    50.0|  50.0|               5.0|\n",
      "+-------------+--------+----------+--------+--------+------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.withColumn('discount', col(\"subtotal\") * 0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00298c10-38da-4e35-9e77-f9521e453d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+\n",
      "|order_item_id|order_id|product_id|subtotal|\n",
      "+-------------+--------+----------+--------+\n",
      "|            1|       1|       957|  299.98|\n",
      "|            2|       2|      1073|  199.99|\n",
      "|            3|       2|       502|   250.0|\n",
      "|            4|       2|       403|  129.99|\n",
      "|            5|       4|       897|   49.98|\n",
      "|            6|       4|       365|  299.95|\n",
      "|            7|       4|       502|   150.0|\n",
      "|            8|       4|      1014|  199.92|\n",
      "|            9|       5|       957|  299.98|\n",
      "|           10|       5|       365|  299.95|\n",
      "|           11|       5|      1014|   99.96|\n",
      "|           12|       5|       957|  299.98|\n",
      "|           13|       5|       403|  129.99|\n",
      "|           14|       7|      1073|  199.99|\n",
      "|           15|       7|       957|  299.98|\n",
      "|           16|       7|       926|   79.95|\n",
      "|           17|       8|       365|  179.97|\n",
      "|           18|       8|       365|  299.95|\n",
      "|           19|       8|      1014|  199.92|\n",
      "|           20|       8|       502|    50.0|\n",
      "+-------------+--------+----------+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.drop(\"quantity\")\\\n",
    "          .drop(\"price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82384687-fd54-4496-84fa-b52f5f9015ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+------+------+\n",
      "|order_item_id|order_id|product_id|quantity|subtotal| price|Status|\n",
      "+-------------+--------+----------+--------+--------+------+------+\n",
      "|            1|       1|       957|       1|  299.98|299.98|   LOW|\n",
      "|            2|       2|      1073|       1|  199.99|199.99|   LOW|\n",
      "|            3|       2|       502|       5|   250.0|  50.0|Mediam|\n",
      "|            4|       2|       403|       1|  129.99|129.99|   LOW|\n",
      "|            5|       4|       897|       2|   49.98| 24.99|   LOW|\n",
      "|            6|       4|       365|       5|  299.95| 59.99|Mediam|\n",
      "|            7|       4|       502|       3|   150.0|  50.0|   LOW|\n",
      "|            8|       4|      1014|       4|  199.92| 49.98|Mediam|\n",
      "|            9|       5|       957|       1|  299.98|299.98|   LOW|\n",
      "|           10|       5|       365|       5|  299.95| 59.99|Mediam|\n",
      "|           11|       5|      1014|       2|   99.96| 49.98|   LOW|\n",
      "|           12|       5|       957|       1|  299.98|299.98|   LOW|\n",
      "|           13|       5|       403|       1|  129.99|129.99|   LOW|\n",
      "|           14|       7|      1073|       1|  199.99|199.99|   LOW|\n",
      "|           15|       7|       957|       1|  299.98|299.98|   LOW|\n",
      "|           16|       7|       926|       5|   79.95| 15.99|Mediam|\n",
      "|           17|       8|       365|       3|  179.97| 59.99|   LOW|\n",
      "|           18|       8|       365|       5|  299.95| 59.99|Mediam|\n",
      "|           19|       8|      1014|       4|  199.92| 49.98|Mediam|\n",
      "|           20|       8|       502|       1|    50.0|  50.0|   LOW|\n",
      "+-------------+--------+----------+--------+--------+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "ordItems_df.withColumn(\"Status\",\n",
    "                      when(col(\"quantity\") >5 , \"HIGH\")\\\n",
    "                      .when(col(\"quantity\") >3 , \"Mediam\").otherwise(\"LOW\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d8f73279-ff97-4a90-ae7b-dbd301d783df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|order_item_id|order_id|product_id|quantity|subtotal|price|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|            3|       2|       502|       5|   250.0| 50.0|\n",
      "|            6|       4|       365|       5|  299.95|59.99|\n",
      "|           10|       5|       365|       5|  299.95|59.99|\n",
      "|           16|       7|       926|       5|   79.95|15.99|\n",
      "|           18|       8|       365|       5|  299.95|59.99|\n",
      "|           33|      11|      1014|       5|   249.9|49.98|\n",
      "|           37|      12|       191|       5|  499.95|99.99|\n",
      "|           38|      12|       502|       5|   250.0| 50.0|\n",
      "|           49|      16|       365|       5|  299.95|59.99|\n",
      "|           60|      20|       502|       5|   250.0| 50.0|\n",
      "|           63|      20|       365|       5|  299.95|59.99|\n",
      "|           71|      24|       502|       5|   250.0| 50.0|\n",
      "|           84|      29|      1014|       5|   249.9|49.98|\n",
      "|           89|      31|       191|       5|  499.95|99.99|\n",
      "|          107|      42|       365|       5|  299.95|59.99|\n",
      "|          113|      45|       627|       5|  199.95|39.99|\n",
      "|          115|      45|       924|       5|   79.95|15.99|\n",
      "|          128|      52|      1014|       5|   249.9|49.98|\n",
      "|          172|      71|       191|       5|  499.95|99.99|\n",
      "|          179|      73|      1014|       5|   249.9|49.98|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.filter(col(\"quantity\") >=5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "262e1c06-0ea2-4f78-8518-db5ed48d81a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|order_item_id|order_id|product_id|quantity|subtotal|price|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|            3|       2|       502|       5|   250.0| 50.0|\n",
      "|           38|      12|       502|       5|   250.0| 50.0|\n",
      "|           60|      20|       502|       5|   250.0| 50.0|\n",
      "|           71|      24|       502|       5|   250.0| 50.0|\n",
      "|          244|     107|       502|       5|   250.0| 50.0|\n",
      "|          282|     120|       502|       5|   250.0| 50.0|\n",
      "|          288|     121|       502|       5|   250.0| 50.0|\n",
      "|          311|     132|       502|       5|   250.0| 50.0|\n",
      "|          349|     148|       502|       5|   250.0| 50.0|\n",
      "|          482|     197|       502|       5|   250.0| 50.0|\n",
      "|          485|     200|       502|       5|   250.0| 50.0|\n",
      "|          529|     219|       502|       5|   250.0| 50.0|\n",
      "|          565|     229|       502|       5|   250.0| 50.0|\n",
      "|          640|     254|       502|       5|   250.0| 50.0|\n",
      "|          658|     260|       502|       5|   250.0| 50.0|\n",
      "|          761|     303|       502|       5|   250.0| 50.0|\n",
      "|          771|     307|       502|       5|   250.0| 50.0|\n",
      "|          806|     324|       502|       5|   250.0| 50.0|\n",
      "|          850|     343|       502|       5|   250.0| 50.0|\n",
      "|         1082|     437|       502|       5|   250.0| 50.0|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "ordItems_df.where( (col(\"quantity\") >4) & (col(\"product_id\") ==502) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abcd785e-56d8-46d5-b340-b0628a6bfebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"order_date\", TimestampType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"order_status\", StringType(), True),\n",
    "        \n",
    "])\n",
    "df = spark.read.csv('c:/data/Orders',schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0634b20-f418-4c33-b682-8313e2453c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92eb956e-22a1-48ac-8f67-f8a5e251c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|order_id|         order_date|\n",
      "+--------+-------------------+\n",
      "|       1|2013-07-25 00:00:00|\n",
      "|       2|2013-07-25 00:00:00|\n",
      "|       3|2013-07-25 00:00:00|\n",
      "|       4|2013-07-25 00:00:00|\n",
      "|       5|2013-07-25 00:00:00|\n",
      "|       6|2013-07-25 00:00:00|\n",
      "|       7|2013-07-25 00:00:00|\n",
      "|       8|2013-07-25 00:00:00|\n",
      "|       9|2013-07-25 00:00:00|\n",
      "|      10|2013-07-25 00:00:00|\n",
      "|      11|2013-07-25 00:00:00|\n",
      "|      12|2013-07-25 00:00:00|\n",
      "|      13|2013-07-25 00:00:00|\n",
      "|      14|2013-07-25 00:00:00|\n",
      "|      15|2013-07-25 00:00:00|\n",
      "|      16|2013-07-25 00:00:00|\n",
      "|      17|2013-07-25 00:00:00|\n",
      "|      18|2013-07-25 00:00:00|\n",
      "|      19|2013-07-25 00:00:00|\n",
      "|      20|2013-07-25 00:00:00|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"order_id\",\"order_date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2092bce-0309-42c5-b0ca-67284d02d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------+\n",
      "|order_id|         order_date|   order_status|\n",
      "+--------+-------------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|     PROCESSING|\n",
      "+--------+-------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(df.order_id,df.order_date,df.order_status).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba673abe-2b7d-4715-893f-a86b2d49ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------------+\n",
      "| id|order_id|               date|\n",
      "+---+--------+-------------------+\n",
      "|  1|     100|2013-07-25 00:00:00|\n",
      "|  2|     200|2013-07-25 00:00:00|\n",
      "|  3|     300|2013-07-25 00:00:00|\n",
      "|  4|     400|2013-07-25 00:00:00|\n",
      "|  5|     500|2013-07-25 00:00:00|\n",
      "|  6|     600|2013-07-25 00:00:00|\n",
      "|  7|     700|2013-07-25 00:00:00|\n",
      "|  8|     800|2013-07-25 00:00:00|\n",
      "|  9|     900|2013-07-25 00:00:00|\n",
      "| 10|    1000|2013-07-25 00:00:00|\n",
      "| 11|    1100|2013-07-25 00:00:00|\n",
      "| 12|    1200|2013-07-25 00:00:00|\n",
      "| 13|    1300|2013-07-25 00:00:00|\n",
      "| 14|    1400|2013-07-25 00:00:00|\n",
      "| 15|    1500|2013-07-25 00:00:00|\n",
      "| 16|    1600|2013-07-25 00:00:00|\n",
      "| 17|    1700|2013-07-25 00:00:00|\n",
      "| 18|    1800|2013-07-25 00:00:00|\n",
      "| 19|    1900|2013-07-25 00:00:00|\n",
      "| 20|    2000|2013-07-25 00:00:00|\n",
      "+---+--------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"order_id\").alias(\"id\"),\n",
    "          (col(\"order_id\") * 100).alias(\"order_id\"),\n",
    "          col(\"order_date\").alias(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf5bc87e-6c96-496a-9f2f-7d600ff89144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|order_id|         order_date|customer_id|\n",
      "+--------+-------------------+-----------+\n",
      "|       1|2013-07-25 00:00:00|      11599|\n",
      "|       2|2013-07-25 00:00:00|        256|\n",
      "|       3|2013-07-25 00:00:00|      12111|\n",
      "|       4|2013-07-25 00:00:00|       8827|\n",
      "|       5|2013-07-25 00:00:00|      11318|\n",
      "|       6|2013-07-25 00:00:00|       7130|\n",
      "|       7|2013-07-25 00:00:00|       4530|\n",
      "|       8|2013-07-25 00:00:00|       2911|\n",
      "|       9|2013-07-25 00:00:00|       5657|\n",
      "|      10|2013-07-25 00:00:00|       5648|\n",
      "|      11|2013-07-25 00:00:00|        918|\n",
      "|      12|2013-07-25 00:00:00|       1837|\n",
      "|      13|2013-07-25 00:00:00|       9149|\n",
      "|      14|2013-07-25 00:00:00|       9842|\n",
      "|      15|2013-07-25 00:00:00|       2568|\n",
      "|      16|2013-07-25 00:00:00|       7276|\n",
      "|      17|2013-07-25 00:00:00|       2667|\n",
      "|      18|2013-07-25 00:00:00|       1205|\n",
      "|      19|2013-07-25 00:00:00|       9488|\n",
      "|      20|2013-07-25 00:00:00|       9198|\n",
      "+--------+-------------------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select( [x for x in df.columns if x !='order_status']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa21b838-3a9f-49c1-a9be-f006ab2cd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------+\n",
      "|order_id|order_date         |order_status   |\n",
      "+--------+-------------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00|PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00|PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00|CLOSED         |\n",
      "|13      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00|PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00|COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00|COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00|CLOSED         |\n",
      "|19      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00|PROCESSING     |\n",
      "+--------+-------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"order_id\",\"order_date\",\"upper(order_status) as order_status\" ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1168a142-0c2c-46b9-b20a-2b2eed00ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "|order_id|         order_date|customer_id|   order_status|order_status_upper|\n",
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|            CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|          COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|            CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|          COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|          COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|          COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|        PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|    PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|            CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|        PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|          COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|          COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|            CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|        PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"order_status_upper\", upper(col( \"order_status\"))).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d746848e-47b4-4019-ab11-3601f2dc3efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "|order_id|         order_date|customer_id|   order_status|order_id * 100|\n",
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|           100|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|           200|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|           300|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|           400|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|           500|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|           600|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|           700|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|           800|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|           900|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|          1000|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|          1100|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|          1200|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|          1300|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|          1400|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|          1500|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|          1600|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|          1700|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|          1800|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|          1900|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|          2000|\n",
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"order_id * 100\", col(\"order_id\") * 100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06813605-0ff2-47d9-9765-ff49b72c6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+---------------+\n",
      "|orderId|         order_date|customer_id|   order_status|\n",
      "+-------+-------------------+-----------+---------------+\n",
      "|      1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|      6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|      7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|      8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|      9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|     11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|     12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|     13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|     14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|     15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|     16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|     17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|     18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|     19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|     20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+-------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"order_id\", \"orderId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886355e-34c5-47c1-9571-3b5637eaf0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItems_df.withColumn(\"Type\", \"quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a581d3d9-14dd-4932-98aa-c005884fbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Ravi\", \"salary\": 50000, \"deptno\":10},\n",
    "    {\"id\": 2, \"name\": \"Priya\", \"salary\": 60000, \"deptno\":10},\n",
    "    {\"id\": 3, \"name\": \"John\", \"salary\": 45000, \"deptno\":20},\n",
    "    {\"id\": 4, \"name\": \"Rashmi\", \"salary\": 80000, \"deptno\":20},\n",
    "    {\"id\": 5, \"name\": \"Prem\", \"salary\": 25000, \"deptno\":30},\n",
    "    {\"id\": 6, \"name\": \"Raheem\", \"salary\": 50000, \"deptno\":30},\n",
    "    {\"id\": 7, \"name\": \"Sunil\", \"salary\": 30000, \"deptno\":10},\n",
    "    {\"id\": 8, \"name\": \"John\", \"salary\": 35000, \"deptno\":10},\n",
    "    {\"id\": 9, \"name\": \"Susil\", \"salary\": 45000, \"deptno\":20},\n",
    "    {\"id\": 10, \"name\": \"Jothi\", \"salary\": 75000, \"deptno\":10}    \n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2191d1b1-7fc6-4582-8c03-9ed280287a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c157e0c0-8ac6-47c3-a04e-5db95551faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+------+\n",
      "|deptno| id|  name|salary|Status|\n",
      "+------+---+------+------+------+\n",
      "|    10|  1|  Ravi| 50000|   LOW|\n",
      "|    10|  2| Priya| 60000|  HIGH|\n",
      "|    20|  3|  John| 45000|   LOW|\n",
      "|    20|  4|Rashmi| 80000|  HIGH|\n",
      "|    30|  5|  Prem| 25000|   LOW|\n",
      "|    30|  6|Raheem| 50000|   LOW|\n",
      "|    10|  7| Sunil| 30000|   LOW|\n",
      "|    10|  8|  John| 35000|   LOW|\n",
      "|    20|  9| Susil| 45000|   LOW|\n",
      "|    10| 10| Jothi| 75000|  HIGH|\n",
      "+------+---+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Status\",\n",
    "              when(col(\"salary\") > 50000, \"HIGH\").otherwise(\"LOW\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88a5dc43-30ff-4e41-a842-2f370952a246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+----------+------------------+-----------+\n",
      "|deptno| id|  name|salary|name_upper|    salary_plus_10|salary_flag|\n",
      "+------+---+------+------+----------+------------------+-----------+\n",
      "|    10|  1|  Ravi| 50000|      RAVI| 55000.00000000001|        LOW|\n",
      "|    10|  2| Priya| 60000|     PRIYA|           66000.0|       HIGH|\n",
      "|    20|  3|  John| 45000|      JOHN| 49500.00000000001|        LOW|\n",
      "|    20|  4|Rashmi| 80000|    RASHMI|           88000.0|       HIGH|\n",
      "|    30|  5|  Prem| 25000|      PREM|27500.000000000004|        LOW|\n",
      "|    30|  6|Raheem| 50000|    RAHEEM| 55000.00000000001|        LOW|\n",
      "|    10|  7| Sunil| 30000|     SUNIL|           33000.0|        LOW|\n",
      "|    10|  8|  John| 35000|      JOHN|           38500.0|        LOW|\n",
      "|    20|  9| Susil| 45000|     SUSIL| 49500.00000000001|        LOW|\n",
      "|    10| 10| Jothi| 75000|     JOTHI|           82500.0|       HIGH|\n",
      "+------+---+------+------+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df2 = df.withColumns({\n",
    "    \"name_upper\": upper(col(\"name\")),\n",
    "    \"salary_plus_10\": col(\"salary\") * 1.10,\n",
    "    \"salary_flag\": when(col(\"salary\") > 50000, \"HIGH\").otherwise(\"LOW\")\n",
    "})\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2612aa4a-d02f-4c6e-82e8-59d1b5b82c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"order_status\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b3cb69-8af4-4f47-b185-542ef3f35373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  3|Shiva|        HR|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Shiva\", \"HR\"),\n",
    "    (2, \"Reddy\", \"Finance\"),\n",
    "    (3, \"Shiva\", \"HR\"),      # duplicate row\n",
    "    (4, \"Shiva\", \"Marketing\")\n",
    "]\n",
    "\n",
    "df1 = spark.createDataFrame(data, [\"id\", \"name\", \"department\"])\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6030cabe-b330-4d50-a54c-6770dfb19adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  3|Shiva|        HR|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb5d71c-fb58-4400-ab5e-2f72ef80144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  3|Shiva|        HR|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8448a2-3275-4d72-9fc7-50e025ef54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop_duplicates(subset=[\"department\",\"name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e0b7c8-5908-410e-a86a-94891e68c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  2|Reddy|   Finance|\n",
      "|  1|Shiva|        HR|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop_duplicates(subset=[\"name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea374743-c39a-4485-8b55-d6f656112f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|   3|Reddy|  NULL|\n",
      "|NULL|Kumar| 30000|\n",
      "|   5| NULL|  NULL|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Shiva\",    60000),\n",
    "    (2, None,       45000),\n",
    "    (3, \"Reddy\",    None),\n",
    "    (None, \"Kumar\", 30000),\n",
    "    (5, None,       None)\n",
    "]\n",
    "\n",
    "df2 = spark.createDataFrame(data, [\"id\", \"name\", \"salary\"])\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24adde91-0de7-49a6-962e-1d2516367f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|   3|Reddy|  NULL|\n",
      "|NULL|Kumar| 30000|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbb08ce-d0fd-4384-b83d-425d18622e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|NULL|Kumar| 30000|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(subset=[\"salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29c6d0e-a157-4d87-98c2-790a4beba902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Shiva| 60000|\n",
      "|  2| NULL| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(subset=[\"salary\",\"id\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f4dbfb-1f72-4321-942e-ca01b47cffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Shiva| 60000|\n",
      "|  2| NULL| 45000|\n",
      "|  3|Reddy|     0|\n",
      "|  0|Kumar| 30000|\n",
      "|  5| NULL|     0|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill string  columns\n",
    "df2.fillna(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7903a9ae-5baf-48ec-9d31-4609f4e0b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|   3|Reddy|     0|\n",
      "|NULL|Kumar| 30000|\n",
      "|   5| NULL|     0|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.fillna(0, subset=[\"salary\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "529ec1d2-8740-41f0-8f66-67e34c2b02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+-------+\n",
      "|deptno| id|  name|salary|country|\n",
      "+------+---+------+------+-------+\n",
      "|    10|  1|  Ravi| 50000|  India|\n",
      "|    10|  2| Priya| 60000|  India|\n",
      "|    20|  3|  John| 45000|  India|\n",
      "|    20|  4|Rashmi| 80000|  India|\n",
      "|    30|  5|  Prem| 25000|  India|\n",
      "|    30|  6|Raheem| 50000|  India|\n",
      "|    10|  7| Sunil| 30000|  India|\n",
      "|    10|  8|  John| 35000|  India|\n",
      "|    20|  9| Susil| 45000|  India|\n",
      "|    10| 10| Jothi| 75000|  India|\n",
      "+------+---+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add constant column\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"country\", lit(\"India\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a878c51-8d04-4a86-9058-7d889518cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+\n",
      "| id|         name|salary|\n",
      "+---+-------------+------+\n",
      "|  1|        Shiva| 60000|\n",
      "|  2|Not Available| 45000|\n",
      "|  3|        Reddy|     0|\n",
      "| -1|        Kumar| 30000|\n",
      "|  5|Not Available|     0|\n",
      "+---+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.fillna({\n",
    "    \"name\": \"Not Available\",\n",
    "    \"salary\": 0,\n",
    "    \"id\": -1\n",
    "}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fc41b42-4e14-4eee-99d7-5d8097544bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+---------------------+\n",
      "|deptno|id |name  |salary|Name_Country         |\n",
      "+------+---+------+------+---------------------+\n",
      "|10    |1  |Ravi  |50000 |Ravi belongs  India  |\n",
      "|10    |2  |Priya |60000 |Priya belongs  India |\n",
      "|20    |3  |John  |45000 |John belongs  India  |\n",
      "|20    |4  |Rashmi|80000 |Rashmi belongs  India|\n",
      "|30    |5  |Prem  |25000 |Prem belongs  India  |\n",
      "|30    |6  |Raheem|50000 |Raheem belongs  India|\n",
      "|10    |7  |Sunil |30000 |Sunil belongs  India |\n",
      "|10    |8  |John  |35000 |John belongs  India  |\n",
      "|20    |9  |Susil |45000 |Susil belongs  India |\n",
      "|10    |10 |Jothi |75000 |Jothi belongs  India |\n",
      "+------+---+------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit,concat\n",
    "df.withColumn(\"Name_Country\", concat(col(\"name\") , lit(\" belongs  India\")  )).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a016d3b8-5a10-441b-9a33-8fb0c9be48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "+---+-----+----------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32e2e2d-1ae3-4996-83d5-3a2443415ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-----------------+\n",
      "|id |name |department|id_name_dept     |\n",
      "+---+-----+----------+-----------------+\n",
      "|1  |Shiva|HR        |1|Shiva|HR       |\n",
      "|2  |Reddy|Finance   |2|Reddy|Finance  |\n",
      "|3  |Shiva|HR        |3|Shiva|HR       |\n",
      "|4  |Shiva|Marketing |4|Shiva|Marketing|\n",
      "+---+-----+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, concat\n",
    "\n",
    "df2 = df1.withColumn(\n",
    "    \"id_name_dept\",\n",
    "    concat(col(\"id\").cast(\"string\"),lit(\"|\"), col(\"name\"),lit('|'),col(\"department\"))\n",
    ")\n",
    "\n",
    "df2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d488f209-3f31-4105-92f0-5d6b29be4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, concat_ws\n",
    "\n",
    "df2 = df1.withColumn(\n",
    "    \"name_dept\",\n",
    "    concat_ws(' ', col(\"name\"), lit(\"belongs to\"), col(\"department\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb76ae0f-b86e-4297-a5ff-6f64655c0ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id| name|                dept|\n",
      "+---+-----+--------------------+\n",
      "|  1|Shiva| Shiva belongs to HR|\n",
      "|  2|Reddy|Reddy belongs to ...|\n",
      "|  3|Shiva| Shiva belongs to HR|\n",
      "|  4|Shiva|Shiva belongs to ...|\n",
      "+---+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(\"id\",\"name\",concat_ws(' ', col(\"name\"), lit(\"belongs to\"), col(\"department\")).alias(\"dept\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "846d055a-7052-49ae-9082-f425297d4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+--------------------+\n",
      "| id| name|department|           name_dept|\n",
      "+---+-----+----------+--------------------+\n",
      "|  1|Shiva|        HR| Shiva belongs to HR|\n",
      "|  2|Reddy|   Finance|Reddy belongs to ...|\n",
      "|  3|Shiva|        HR| Shiva belongs to HR|\n",
      "|  4|Shiva| Marketing|Shiva belongs to ...|\n",
      "+---+-----+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "371bc269-365b-4863-bb68-9b828e941533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+\n",
      "| id|  name|country|\n",
      "+---+------+-------+\n",
      "|  1|  Ravi|  India|\n",
      "|  2| Priya|  India|\n",
      "|  3|  John|  India|\n",
      "|  4|Rashmi|  India|\n",
      "|  5|  Prem|  India|\n",
      "|  6|Raheem|  India|\n",
      "|  7| Sunil|  India|\n",
      "|  8|  John|  India|\n",
      "|  9| Susil|  India|\n",
      "| 10| Jothi|  India|\n",
      "+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\", lit(\"India\").alias(\"country\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "663d416d-360e-49e4-8a4b-b22c98157dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\") > 50000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f904e60-2728-4c6b-8402-6cb2f67ef1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37f64a96-22ba-4f30-a843-cea718837557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+--------------------+\n",
      "|deptno| id|  name|salary|           ename_sal|\n",
      "+------+---+------+------+--------------------+\n",
      "|    10|  2| Priya| 60000|Priya Salary is 6...|\n",
      "|    20|  4|Rashmi| 80000|Rashmi Salary is ...|\n",
      "|    10| 10| Jothi| 75000|Jothi Salary is 7...|\n",
      "+------+---+------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\") > 50000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64ff093f-9342-4940-82ec-c53953521989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ename_sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c8947e5-32fc-41ab-916c-d73bfdd4376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|salary|deptno|\n",
      "+---+------+------+\n",
      "|  1| 50000|    10|\n",
      "|  2| 60000|    10|\n",
      "|  4| 80000|    20|\n",
      "|  7| 30000|    10|\n",
      "|  8| 35000|    10|\n",
      "| 10| 75000|    10|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( (( col(\"deptno\") ==10)  & ( col(\"salary\") > 25000))\n",
    "           |\n",
    "           (( col(\"deptno\") ==20)  & ( col(\"salary\") >50000))\n",
    "         ).select(\"id\",\"salary\",\"deptno\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d160e4-0df2-4bda-a5a6-5acc89c55570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e694c5-4f08-4260-aadf-2cebf826a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f37c06c4-05be-48a4-a265-81621444b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+------+\n",
      "|deptno| id| name|salary|\n",
      "+------+---+-----+------+\n",
      "|    10|  1| Ravi| 50000|\n",
      "|    10|  2|Priya| 60000|\n",
      "|    10| 10|Jothi| 75000|\n",
      "+------+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter using SQL-like string condition\n",
    "df.filter(\"salary > 40000 and deptno ==10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65ccba1f-7fa5-48e1-ae3b-0af4ac824d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~col(\"deptno\").isin(10,20)).orderBy(\"deptno\",ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1badec09-7c61-4203-9be1-c2acf509fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~col(\"deptno\").isin(10,20)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47c496be-7452-4c53-a04b-39cd08f30278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"%em\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d5ac6cb-e950-49bf-bce2-cab7f7ec8217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( ~col(\"name\").like(\"Rav%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0da94f2e-381d-4fe9-b619-b53328a24cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"%em\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0579c702-3ecd-4c36-82b2-eb6386274dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+------+\n",
      "|deptno| id|name|salary|\n",
      "+------+---+----+------+\n",
      "+------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"%Kumar%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7e8a190-d08d-42dd-9167-84cd28e8f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\").between(20000, 50000)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59bccd28-9c1f-4e88-aa1f-47448000cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~col(\"salary\").between(20000, 50000)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f10bce5-95f7-427d-920d-3550e798fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\",\"salary\").filter(col(\"salary\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea21bac5-3fa5-40ed-a52a-80d06f4a90a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|  name|salary|\n",
      "+---+------+------+\n",
      "|  1|  Ravi| 50000|\n",
      "|  2| Priya| 60000|\n",
      "|  3|  John| 45000|\n",
      "|  4|Rashmi| 80000|\n",
      "|  5|  Prem| 25000|\n",
      "|  6|Raheem| 50000|\n",
      "|  7| Sunil| 30000|\n",
      "|  8|  John| 35000|\n",
      "|  9| Susil| 45000|\n",
      "| 10| Jothi| 75000|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\",\"salary\").filter(~col(\"salary\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c3a33aa-1452-4351-ba6c-0e08af42c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  2| NULL| 60000|\n",
      "|  3| John|  NULL|\n",
      "|  4| NULL|  NULL|\n",
      "|  5|Priya| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"Ravi\", 50000),\n",
    "    (2, None, 60000),\n",
    "    (3, \"John\", None),\n",
    "    (4, None, None),\n",
    "    (5, \"Priya\", 45000)\n",
    "]\n",
    "\n",
    "df2 = spark.createDataFrame(data, [\"id\", \"name\", \"salary\"])\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70245c93-acef-4e86-bed9-679daaf8d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3|John|  NULL|\n",
      "|  4|NULL|  NULL|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(col(\"salary\").isNull()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3103197f-0f59-43b7-80af-4e56e0d6f2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  3| John|  NULL|\n",
      "|  5|Priya| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(col(\"name\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cbe78d9-7e99-4528-a9e1-7d86d62f7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where( (col(\"salary\") >50000) | (col(\"deptno\") ==10)   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87d19b91-c716-4b95-b645-d4649a6bc66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"salary\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab944538-9b30-4271-9b6e-e69c64be174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"salary\").asc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9db2fbb7-5515-4e48-adfc-ae9337cb1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\n",
    "    col(\"deptno\").asc(),\n",
    "    col(\"salary\").desc()\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "458d61a9-64d9-4740-a7ed-ba352bf860d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76f028ea-67f0-48a5-8c6d-dae7d821815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4417cf0d-bc2f-4052-bb3f-d314fdbe061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc9f0390-9fb1-4f93-9381-50d4b1fdc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sortWithinPartitions( \"salary\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb681305-95fb-4511-a4c5-fc3fa3160cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deptno=10, id=1, name='Ravi', salary=50000),\n",
       " Row(deptno=10, id=2, name='Priya', salary=60000),\n",
       " Row(deptno=20, id=3, name='John', salary=45000),\n",
       " Row(deptno=20, id=4, name='Rashmi', salary=80000)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed289a41-c3f7-4e9d-b413-71d7366a61ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deptno=10, id=7, name='Sunil', salary=30000),\n",
       " Row(deptno=10, id=8, name='John', salary=35000),\n",
       " Row(deptno=20, id=9, name='Susil', salary=45000),\n",
       " Row(deptno=10, id=10, name='Jothi', salary=75000)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cefc691b-e916-45ae-8609-19b8a00ad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set operation\n",
    "df1 = spark.createDataFrame(\n",
    "    [(1, \"A\"), (2, \"B\"), (3, \"C\")],\n",
    "    [\"id\", \"val\"]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(3, \"C\"), (4, \"D\")],\n",
    "    [\"id\", \"val\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a62f4d0-1419-456e-88e0-87a209e40885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59fc3a44-aaac-4222-a067-60e8c7986853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c1a0833-d8cf-4721-a7a8-9a94e62333fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc9ff296-ce38-46ae-a193-cdaba645970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data=(('a',1),('b',2)),schema=('col1 string,col2 int'))\n",
    "df4 = spark.createDataFrame(data=((2,'b'),(3,'c')),schema=('col2 int,col1 string'))\n",
    "df3.unionByName(df4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09ef8fa1-2922-41ae-bece-b4ae8d947f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(data=(('a',1),('a',1),('b',2)),schema=('col1 string,col2 int')) \n",
    "df2 = spark.createDataFrame(data=(('a',1),('a',1),('c',2)),schema=('col1 string,col2 int'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "456002cd-d21c-46d1-945f-6eb0b606bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0da0bdd7-9b63-42d4-8ece-8292a06abc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   1|\n",
      "|   c|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f810724-bc9a-4f4e-9617-1f72699d4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f001590f-a137-406e-9dbd-dfdf5eb74295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersectAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adc846df-252c-4c8a-b84b-487d93925957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   b|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40deea86-52c0-41e0-9017-3fa6dc215e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+\n",
      "|emp_id| ename|dept_id|\n",
      "+------+------+-------+\n",
      "|     1| Smith|     10|\n",
      "|     2| Allen|     20|\n",
      "|     3|  Ward|     10|\n",
      "|     4| Jones|     30|\n",
      "|     5|Martin|   NULL|\n",
      "+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# EMP schema\n",
    "emp_schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),\n",
    "    StructField(\"ename\", StringType(), True),\n",
    "    StructField(\"dept_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "emp_data = [\n",
    "    (1, \"Smith\", 10),\n",
    "    (2, \"Allen\", 20),\n",
    "    (3, \"Ward\", 10),\n",
    "    (4, \"Jones\", 30),\n",
    "    (5, \"Martin\", None)\n",
    "]\n",
    "\n",
    "emp = spark.createDataFrame(emp_data, emp_schema)\n",
    "\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05a70a5b-195a-4da6-86c7-2d9d5e67aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|dept_id|     dname|\n",
      "+-------+----------+\n",
      "|     10|ACCOUNTING|\n",
      "|     20|  RESEARCH|\n",
      "|     30|     SALES|\n",
      "|     40|OPERATIONS|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEPT schema\n",
    "dept_schema = StructType([\n",
    "    StructField(\"dept_id\", IntegerType(), True),\n",
    "    StructField(\"dname\", StringType(), True)\n",
    "])\n",
    "\n",
    "dept_data = [\n",
    "    (10, \"ACCOUNTING\"),\n",
    "    (20, \"RESEARCH\"),\n",
    "    (30, \"SALES\"),\n",
    "    (40, \"OPERATIONS\")\n",
    "]\n",
    "\n",
    "dept = spark.createDataFrame(dept_data, dept_schema)\n",
    "dept.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "622cf2bd-3e10-4cff-a85d-ea38c96a1733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+----------+\n",
      "|emp_id|ename|dept_id|     dname|\n",
      "+------+-----+-------+----------+\n",
      "|     1|Smith|     10|ACCOUNTING|\n",
      "|     3| Ward|     10|ACCOUNTING|\n",
      "|     2|Allen|     20|  RESEARCH|\n",
      "|     4|Jones|     30|     SALES|\n",
      "+------+-----+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emp.join(dept, \"dept_id\", how= \"inner\").\\\n",
    "    select(\"emp_id\",\"ename\",\"dept_id\",\"dname\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ff11b5b9-7d3c-4eee-8915-0476685e56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|dept_id|emp_id| ename|     dname|\n",
      "+-------+------+------+----------+\n",
      "|     10|     1| Smith|ACCOUNTING|\n",
      "|     20|     2| Allen|  RESEARCH|\n",
      "|     10|     3|  Ward|ACCOUNTING|\n",
      "|     30|     4| Jones|     SALES|\n",
      "|   NULL|     5|Martin|      NULL|\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"left\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c449a8d-49e4-4ee0-862f-7341067b4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+----------+\n",
      "|dept_id|emp_id|ename|     dname|\n",
      "+-------+------+-----+----------+\n",
      "|     10|     3| Ward|ACCOUNTING|\n",
      "|     10|     1|Smith|ACCOUNTING|\n",
      "|     20|     2|Allen|  RESEARCH|\n",
      "|     30|     4|Jones|     SALES|\n",
      "|     40|  NULL| NULL|OPERATIONS|\n",
      "+-------+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"right\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e6f36870-d12f-4883-ba47-37507b0a3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|dept_id|emp_id| ename|     dname|\n",
      "+-------+------+------+----------+\n",
      "|   NULL|     5|Martin|      NULL|\n",
      "|     10|     3|  Ward|ACCOUNTING|\n",
      "|     10|     1| Smith|ACCOUNTING|\n",
      "|     20|     2| Allen|  RESEARCH|\n",
      "|     30|     4| Jones|     SALES|\n",
      "|     40|  NULL|  NULL|OPERATIONS|\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"full\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab4f63de-279d-473d-83d1-9508d4dfda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|dept_id|emp_id|ename|\n",
      "+-------+------+-----+\n",
      "|     10|     1|Smith|\n",
      "|     10|     3| Ward|\n",
      "|     20|     2|Allen|\n",
      "|     30|     4|Jones|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Returns only employees whose dept exists.\n",
    "emp.join(dept, \"dept_id\", \"leftsemi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74a540a0-31c8-48fd-9d73-cd743ffb0996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|dept_id|emp_id| ename|\n",
      "+-------+------+------+\n",
      "|   NULL|     5|Martin|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Employees who do not have a matching department.\n",
    "emp.join(dept, \"dept_id\", \"leftanti\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "447942e1-1b88-4beb-bade-52fdbe933cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+-------+----------+\n",
      "|emp_id| ename|dept_id|dept_id|     dname|\n",
      "+------+------+-------+-------+----------+\n",
      "|     1| Smith|     10|     10|ACCOUNTING|\n",
      "|     5|Martin|   NULL|     10|ACCOUNTING|\n",
      "|     4| Jones|     30|     10|ACCOUNTING|\n",
      "|     3|  Ward|     10|     10|ACCOUNTING|\n",
      "|     2| Allen|     20|     10|ACCOUNTING|\n",
      "|     5|Martin|   NULL|     40|OPERATIONS|\n",
      "|     4| Jones|     30|     40|OPERATIONS|\n",
      "|     3|  Ward|     10|     40|OPERATIONS|\n",
      "|     2| Allen|     20|     40|OPERATIONS|\n",
      "|     1| Smith|     10|     40|OPERATIONS|\n",
      "|     5|Martin|   NULL|     20|  RESEARCH|\n",
      "|     4| Jones|     30|     20|  RESEARCH|\n",
      "|     3|  Ward|     10|     20|  RESEARCH|\n",
      "|     2| Allen|     20|     20|  RESEARCH|\n",
      "|     1| Smith|     10|     20|  RESEARCH|\n",
      "|     5|Martin|   NULL|     30|     SALES|\n",
      "|     4| Jones|     30|     30|     SALES|\n",
      "|     3|  Ward|     10|     30|     SALES|\n",
      "|     2| Allen|     20|     30|     SALES|\n",
      "|     1| Smith|     10|     30|     SALES|\n",
      "+------+------+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.crossJoin(dept).orderBy(\"dname\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
